{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Theoreticl Questions<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:**\n",
    "<br>\n",
    "To evaluate how well our model performs at T1D classification, we need to have evaluation metrics that measures of its performances/accuracy. Which evaluation metric is more important to us: model accuracy or model performance? Give a simple example that illustrates your claim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1:**\n",
    "<br>\n",
    "The model performance would be a better evaluation metric in this case. Model accuracy is just the number of correct predictions made by the model devided by the total number of predictions - which would not be a good model in this case because we have a relatively small number of people in the population with the T1D. For example, if we use a classifier that classifies all patients as being healthy, we would get an accuracy of at least 99.67% (according to the assignment that states that up to 0.33% suffer from T1D), which is a very high accuracy, but this is a terrible classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:**\n",
    "<br>\n",
    "T1D is often associated with other comorbidities such as a heart attack. You are asked to design a ML algorithm to predict which patients are going to suffer a heart attack. Relevant patient features for the algorithm may include blood pressure (BP), body-mass index (BMI), age (A), level of physical activity (P), and income (I). You should choose between two classifiers: the first uses only BP and BMI features and the other one uses all of the features available to you. Explain the pros and cons of each choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2:** \n",
    "\n",
    "**Classifier1**\n",
    "<br>\n",
    "Pros - Easy to visualize data, less weights to train.\n",
    "<br>\n",
    "Cons - Selected feature may not be the best features, the less features we have - the more missing information in one of the features might increase errors in the classification.\n",
    "    \n",
    "**Classifier2**\n",
    "<br>\n",
    "Pros - Contains a wider selection of features which might help get a better classification.\n",
    "<br>\n",
    "Cons - Longer training time, may contain redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:**\n",
    "<br>\n",
    "A histologist wants to use machine learning to tell the difference between pancreas biopsies that show signs of T1D and those that do not. She has already come up with dozens of measurements to take, such as color, size, uniformity and cell-count, but she isnâ€™t sure which model to use. The biopsies are really similar, and it is difficult to distinguish them from the human eye, or by just looking at the features. Which of the following is better: logistic regression, linear SVM or nonlinear SVM? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3:**\n",
    "<br>\n",
    "Since the data is difficult to distinguish by just looking at the features, logistic regression would not be useful for classification, nor would linear SVM, since the data is non-seperable, and therefore we cannot seperate the data using a linear line.\n",
    "In this case, nonlinear SVM would be the most useful method, since it would transform our non-seperable data into a higher dimensional space, where the data might prove to be seperable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:**\n",
    "<br>\n",
    "What are the differences between LR and linear SVM and what is the difference in the effect/concept of their hyper-parameters tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4:** \n",
    "The main difference between LR and Linear SVM is that linear SVM find the \"best\" margin that seperates the classes, while LR does not, and can have different boundaries with different weights (the boundary is not \"optimized\").\n",
    "Another differense is that LR uses a probobilistic approach, while SVM is deterministic.\n",
    "The differnce in the concept of their hyper-parameters tuning is that LR uses a regularization (penalty) - for example, l1 or l2, and the C parameter which gives us the penalty strength. For linear SVM - we use the \"kernel trick\" in order to find the best hypter-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Coding Assignment<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T1D data \n",
    "df_raw = pd.read_csv(\"HW2_data.csv\")\n",
    "df = df_raw.copy()\n",
    "\n",
    "#preprocessing\n",
    "#finding empty cells in dataframe\n",
    "row,col = np.where(pd.isnull(df))\n",
    "#converting Yes/No to 1/0\n",
    "for i in range(2,16):\n",
    "    df.iloc[:,i] = df.iloc[:,i].map({'Yes':1,'No':0})\n",
    "df.iloc[:,16] = df.iloc[:,16].map({'Positive':1,'Negative':0})\n",
    "#converting empty cell to NaN\n",
    "for i,j in zip(row,col):\n",
    "    df.iloc[i,j] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "# feature columns\n",
    "features = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17]\n",
    "X = df.iloc[:,features]\n",
    "# T1D prediction\n",
    "y = df.iloc[:,16]\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization and exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
